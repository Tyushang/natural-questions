{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "RUN_ON = 'kaggle' if os.path.exists('/kaggle') else 'gcp'\n",
    "\n",
    "if RUN_ON == 'gcp':\n",
    "    os.chdir('/home/jupyter/kaggle/working')\n",
    "    sys.path.extend(['../input/bert-joint-baseline/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import bert_utils\n",
    "import modeling\n",
    "import bert_optimization as optimization\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(bert_utils)\n",
    "K.clear_session()\n",
    "\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TDense(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 output_size,\n",
    "                 kernel_initializer=None,\n",
    "                 bias_initializer=\"zeros\",\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_size = output_size\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dtype = tf.as_dtype(self.dtype or tf.keras.backend.floatx())\n",
    "        if not (dtype.is_floating or dtype.is_complex):\n",
    "            raise TypeError(\"Unable to build `TDense` layer with \"\n",
    "                            \"non-floating point (and non-complex) \"\n",
    "                            \"dtype %s\" % (dtype,))\n",
    "        input_shape = tf.TensorShape(input_shape)\n",
    "        if tf.compat.dimension_value(input_shape[-1]) is None:\n",
    "            raise ValueError(\"The last dimension of the inputs to \"\n",
    "                             \"`TDense` should be defined. \"\n",
    "                             \"Found `None`.\")\n",
    "        last_dim = tf.compat.dimension_value(input_shape[-1])\n",
    "        self.input_spec = tf.keras.layers.InputSpec(min_ndim=2, axes={-1: last_dim})\n",
    "        self.kernel = self.add_weight(\n",
    "            \"kernel\",\n",
    "            shape=[self.output_size, last_dim],\n",
    "            initializer=self.kernel_initializer,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True)\n",
    "        self.bias = self.add_weight(\n",
    "            \"bias\",\n",
    "            shape=[self.output_size],\n",
    "            initializer=self.bias_initializer,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True)\n",
    "        super(TDense, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.matmul(x, self.kernel, transpose_b=True) + self.bias\n",
    "\n",
    "\n",
    "class Squeeze(tf.keras.layers.Layer):\n",
    "    def call(self, x, axis=None, name=None):\n",
    "        return tf.squeeze(x, axis, name)\n",
    "\n",
    "\n",
    "def mk_model(config, is_training=False):\n",
    "    if not is_training:\n",
    "        config['hidden_dropout_prob'] = 0.0\n",
    "        config['attention_probs_dropout_prob'] = 0.0\n",
    "    seq_len = config['max_position_embeddings']\n",
    "\n",
    "    #     unique_id = tf.keras.Input(shape=(1,), dtype=tf.int64, name='unique_id')\n",
    "    input_ids = tf.keras.Input(shape=(seq_len,), dtype=tf.int32, name='input_ids')\n",
    "    input_mask = tf.keras.Input(shape=(seq_len,), dtype=tf.int32, name='input_mask')\n",
    "    segment_ids = tf.keras.Input(shape=(seq_len,), dtype=tf.int32, name='segment_ids')\n",
    "    BERT = modeling.BertModel(config=config, name='bert')\n",
    "    pooled_output, sequence_output = BERT(input_word_ids=input_ids,\n",
    "                                          input_mask=input_mask,\n",
    "                                          input_type_ids=segment_ids)\n",
    "\n",
    "    logits = TDense(2, name='logits')(sequence_output)\n",
    "    start_logits, end_logits = tf.split(logits, axis=-1, num_or_size_splits=2, name='split')\n",
    "    start_logits = Squeeze(name='start_logits_or_probs')(start_logits, axis=-1)\n",
    "    end_logits = Squeeze(name='end_logits_or_probs')(end_logits, axis=-1)\n",
    "\n",
    "    ans_type = TDense(5, name='ans_type')(pooled_output)\n",
    "    return tf.keras.Model([input_ for input_ in [input_ids, input_mask, segment_ids]\n",
    "                           if input_ is not None],\n",
    "                          [start_logits, end_logits, ans_type],\n",
    "                          name='bert-baseline')\n",
    "\n",
    "\n",
    "# nq loss function\n",
    "def crossentropy_from_logits(y_true, y_pred):\n",
    "    one_hot_positions = y_true\n",
    "    log_probs = tf.nn.log_softmax(y_pred, axis=-1)\n",
    "    loss = -tf.reduce_mean(\n",
    "        tf.reduce_sum(one_hot_positions * log_probs, axis=-1))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DummyObject:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "\n",
    "def url_exists(url):\n",
    "    \"\"\"test local or gs file exists or not.\"\"\"\n",
    "    from urllib import parse\n",
    "    res = parse.urlparse(url)\n",
    "    if res.scheme == 'gs':\n",
    "        # blob_name has no '/' prefix\n",
    "        bucket_name, blob_name = res.netloc, res.path[1:]\n",
    "        from google.cloud import storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        return blob.exists()\n",
    "    else:\n",
    "        return os.path.exists(res.path)\n",
    "\n",
    "\n",
    "def make_decoder(seq_length, is_training):\n",
    "    if is_training:\n",
    "        feature_description = {\n",
    "            \"unique_ids\": tf.io.FixedLenFeature([], tf.int64),\n",
    "            \"input_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "            \"input_mask\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "            \"segment_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "            \"start_positions\": tf.io.FixedLenFeature([], tf.int64),\n",
    "            \"end_positions\": tf.io.FixedLenFeature([], tf.int64),\n",
    "            \"answer_types\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    else:\n",
    "        feature_description = {\n",
    "            \"unique_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "            \"input_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "            \"input_mask\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "            \"segment_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "        }\n",
    "\n",
    "    def _decode_record(record):\n",
    "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "        example = tf.io.parse_single_example(serialized=record, features=feature_description)\n",
    "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "        # So cast all int64 to int32.\n",
    "        for key in [k for k in example.keys() if k not in ['example_id', 'unique_ids']]:\n",
    "            example[key] = tf.cast(example[key], dtype=tf.int32)\n",
    "        if is_training:\n",
    "            features = {\n",
    "                'input_ids': example['input_ids'],\n",
    "                'input_mask': example['input_mask'],\n",
    "                'segment_ids': example['segment_ids']\n",
    "            }\n",
    "            labels = {\n",
    "                'start_logits_or_probs': tf.one_hot(example['start_positions'],\n",
    "                                                    depth=seq_length, dtype=tf.float32),\n",
    "                'end_logits_or_probs': tf.one_hot(example['end_positions'],\n",
    "                                                  depth=seq_length, dtype=tf.float32),\n",
    "                'ans_type': tf.one_hot(example['answer_types'],\n",
    "                                       depth=len(ANSWER_TYPE_ORDER), dtype=tf.float32)\n",
    "            }\n",
    "            return (features, labels)\n",
    "        else:\n",
    "            return example\n",
    "\n",
    "    return _decode_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "FLAGS = DummyObject(skip_nested_contexts=True,\n",
    "                    max_position=50,\n",
    "                    max_contexts=48,\n",
    "                    max_query_length=64,\n",
    "                    max_seq_length=512,\n",
    "                    doc_stride=128,\n",
    "                    include_unknowns=-1.0,\n",
    "                    n_best_size=20,\n",
    "                    max_answer_length=30,\n",
    "                    batch_size=64,\n",
    "                    is_training=True,\n",
    "                    #                     train_num_precomputed=494670,\n",
    "                    train_num_precomputed=200 * 64,\n",
    "                    learning_rate=3e-5,\n",
    "                    num_train_epochs=3,\n",
    "                    )\n",
    "\n",
    "if RUN_ON == 'gcp':\n",
    "    INPUT_PATH = 'gs://tyu-kaggle/input/'\n",
    "else:\n",
    "    INPUT_PATH = '../input/'\n",
    "BERT_CONFIG_PATH = os.path.join('../input', 'bert-joint-baseline/bert_config.json')\n",
    "CKPT_PATH = os.path.join(INPUT_PATH, 'bert-joint-baseline/model_cpkt-1')\n",
    "MODEL_SAVE_PATH = './bert_trained/weights.h5'\n",
    "VOCAB_PATH = os.path.join(INPUT_PATH, 'bert-joint-baseline/vocab-nq.txt')\n",
    "\n",
    "NQ_TEST_JSONL_PATH = '../input/tensorflow2-question-answering/simplified-nq-test.jsonl'\n",
    "NQ_TRAIN_JSONL_PATH = '../input/tensorflow2-question-answering/simplified-nq-train.jsonl'\n",
    "\n",
    "NQ_TEST_TFRECORD_PATH = './nq-test.tfrecords'\n",
    "NQ_TRAIN_TFRECORD_PATH = os.path.join(INPUT_PATH, 'bert-joint-baseline/nq-train.tfrecords')\n",
    "\n",
    "SAMPLE_SUBMISSION_PATH = '../input/tensorflow2-question-answering/sample_submission.csv'\n",
    "\n",
    "TEST_DS_TYPE = 'public' if os.path.getsize(NQ_TEST_JSONL_PATH) < 20000000 else 'private'\n",
    "\n",
    "ANSWER_TYPE_ORDER = ['UNKNOWN', 'YES', 'NO', 'SHORT', 'LONG']\n",
    "\n",
    "with open(BERT_CONFIG_PATH, 'r') as f:\n",
    "    config = json.load(f)\n",
    "print(json.dumps(config, indent=4))\n",
    "\n",
    "n_train_instances = FLAGS.train_num_precomputed\n",
    "n_total_train_steps = int(FLAGS.num_train_epochs * n_train_instances / FLAGS.batch_size)\n",
    "n_epochs = FLAGS.num_train_epochs\n",
    "n_steps_per_epoch = n_train_instances // FLAGS.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"intermediate_size\": 4096,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"hidden_size\": 1024,\n",
      "    \"vocab_size\": 30522,\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"num_hidden_layers\": 24,\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"attention_probs_dropout_prob\": 0.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', TPU.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['10.254.212.146:8470']\n",
      "WARNING:tensorflow:TPU system tyu has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system tyu has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: tyu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: tyu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = mk_model(config, is_training=True)\n",
    "    model.summary()\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    ckpt.restore(CKPT_PATH).assert_consumed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert-baseline\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BertModel)                ((None, 1024), (None 335141888   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "logits (TDense)                 (None, 512, 2)       2050        bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 512, 1), (No 0           logits[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "start_logits_or_probs (Squeeze) (None, 512)          0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "end_logits_or_probs (Squeeze)   (None, 512)          0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type (TDense)               (None, 5)            5125        bert[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 335,149,063\n",
      "Trainable params: 335,149,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "raw_ds = tf.data.TFRecordDataset(NQ_TRAIN_TFRECORD_PATH)\n",
    "if FLAGS.is_training:\n",
    "    raw_ds = raw_ds.repeat()\n",
    "    raw_ds = raw_ds.shuffle(buffer_size=100)\n",
    "decoded_ds = raw_ds.map(make_decoder(seq_length=FLAGS.max_seq_length, is_training=FLAGS.is_training))\n",
    "batched_ds = decoded_ds.batch(batch_size=FLAGS.batch_size, drop_remainder=(TPU is not None))\n",
    "\n",
    "optimizer = optimization.create_optimizer(FLAGS.learning_rate,\n",
    "                                          n_total_train_steps,\n",
    "                                          num_warmup_steps=None)\n",
    "model.compile(optimizer,\n",
    "              loss={\n",
    "                  'start_logits_or_probs': crossentropy_from_logits,\n",
    "                  'end_logits_or_probs': crossentropy_from_logits,\n",
    "                  'ans_type': crossentropy_from_logits},\n",
    "              loss_weights={\n",
    "                  'start_logits_or_probs': 1,\n",
    "                  'end_logits_or_probs': 1,\n",
    "                  'ans_type': 1})\n",
    "hist = model.fit(batched_ds, steps_per_epoch=n_steps_per_epoch, epochs=n_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200 steps\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer-7.constants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer-7.constants\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer-8.constants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer-8.constants\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 191s 956ms/step - loss: 2.7454 - start_logits_or_probs_loss: 1.1519 - end_logits_or_probs_loss: 1.1816 - ans_type_loss: 0.4319\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 86s 431ms/step - loss: 2.5518 - start_logits_or_probs_loss: 1.0752 - end_logits_or_probs_loss: 1.0691 - ans_type_loss: 0.4429\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 86s 432ms/step - loss: 2.3753 - start_logits_or_probs_loss: 0.9830 - end_logits_or_probs_loss: 1.0002 - ans_type_loss: 0.4124\n"
     ]
    }
   ],
   "source": [
    "# raw_ds = tf.data.TFRecordDataset(NQ_TFRECORD_PATH)\n",
    "# decoded_ds = raw_ds.map(make_decoder(seq_length=FLAGS.max_seq_length, is_training=FLAGS.is_training))\n",
    "# batched_ds = decoded_ds.batch(batch_size=32, drop_remainder=(TPU is not None))\n",
    "# batched_ds.element_spec\n",
    "# for x, y in batched_ds:\n",
    "#     print(y)\n",
    "#     break\n",
    "model.save_weights(MODEL_SAVE_PATH)\n",
    "\n",
    "\n",
    "# model.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls bert_trained - lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}